{
 "cells": [
  {
   "cell_type": "code",
   "id": "8baf3e70-686d-4164-87d3-5f0d5f80486c",
   "metadata": {},
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from nervaluate import Evaluator\n",
    "from transformers import TrainerCallback\n",
    "from ray import train, tune\n",
    "from ray.air.integrations.wandb import WandbLoggerCallback\n",
    "from ray.train.huggingface.transformers import prepare_trainer\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "\n",
    "from gliner import GLiNER\n",
    "from gliner.training import Trainer, TrainingArguments\n",
    "from gliner.data_processing.collator import DataCollatorWithPadding\n",
    "from gliner.data_processing import GLiNERDataset\n",
    "\n",
    "from utils import formatting_prompts_func, convert_to_gliner_dataset, combine_entities"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ds = load_dataset(\"jjzha/skillspan\")",
   "id": "9541de136c8bc3f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4e4648bc-456c-41f1-b454-1ce4e723ad5f",
   "metadata": {},
   "source": [
    "ds = load_dataset(\"jjzha/skillspan\")\n",
    "ds = ds.map(formatting_prompts_func)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d146be80-4267-4aa4-bc92-39f1f7ee0cb8",
   "metadata": {},
   "source": "data = convert_to_gliner_dataset(ds['train'])",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "34f2869b-08ef-4a4c-b3ff-5d0dc306aa3a",
   "metadata": {},
   "source": "train_data = data",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c510a2a4-5ffc-44b3-a3b4-95a9dde91c2f",
   "metadata": {},
   "source": [
    "ds['validation'] = ds['validation'].map(function=combine_entities, batched=False)\n",
    "ds['test'] = ds['test'].map(function=combine_entities, batched=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6927bbda-74d0-4cb5-9217-b98ae5e58fc3",
   "metadata": {},
   "source": [
    "class MyCallback(TrainerCallback):\n",
    "\n",
    "    def on_log(self, args, state, control, model, tokenizer, **kwargs):\n",
    "        labels = [\"Skill\", \"Knowledge\"]\n",
    "        pred_gli = []\n",
    "\n",
    "        sentences = ds['validation']['sentence'][:]\n",
    "        batch_size = 64\n",
    "        # Generate batches\n",
    "        for i in range(0, len(sentences), batch_size):\n",
    "            # Yield successive batches of size batch_size\n",
    "            text = sentences[i:i + batch_size]\n",
    "            entities = model.batch_predict_entities(text, labels, threshold=0.82)\n",
    "            pred_gli.extend(entities)\n",
    "        \n",
    "        evaluator = Evaluator(ds['validation']['knowledge_and_skill'][:], pred_gli, tags=['Skill', 'Knowledge'])\n",
    "        # Returns overall metrics and metrics for each tag\n",
    "        results, results_per_tag, result_indices, result_indices_by_tag = evaluator.evaluate()\n",
    "        f1 = {\"f1\": results['strict']['f1']}\n",
    "        train.report(metrics=f1)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "caab35c3-a8e7-401b-931e-f3c8e2cd8190",
   "metadata": {},
   "source": [
    "def train_gliner(config):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # Data Setup\n",
    "    model = GLiNER.from_pretrained(\"EmergentMethods/gliner_small_news-v2.1\",model_max_length=512)\n",
    "    train_dataset = GLiNERDataset(train_data, model.config, data_processor=model.data_processor)\n",
    "    data_collator = DataCollatorWithPadding(model.config)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    max_steps = config['max_steps']\n",
    "    logging_steps = 10\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=train.get_context().get_trial_dir(),\n",
    "        do_eval = False,\n",
    "        learning_rate=config['lr'],\n",
    "        weight_decay=config['weight_decay'],\n",
    "        others_lr= config['others_lr'],\n",
    "        others_weight_decay=0.01,\n",
    "        lr_scheduler_type=config['scheduler'], #cosine\n",
    "        optim = config['optim'],\n",
    "        warmup_ratio=0.1,\n",
    "        max_grad_norm = config['max_grad_norm'],\n",
    "        per_device_train_batch_size=config['batch_size'],\n",
    "        per_device_eval_batch_size=8,\n",
    "        max_steps = max_steps,\n",
    "        logging_steps = logging_steps,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps = logging_steps*2,\n",
    "        save_total_limit = 2,\n",
    "        dataloader_num_workers = 8,\n",
    "        use_cpu = False,\n",
    "        report_to=\"none\",\n",
    "        )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        tokenizer=model.data_processor.transformer_tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        callbacks=[MyCallback()]\n",
    "    )\n",
    "    trainer = prepare_trainer(trainer)\n",
    "    trainer.train()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "38945604-bd40-49fe-9971-aab4ed96e396",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "current_datetime = datetime.now()\n",
    "formatted_datetime = current_datetime.strftime(\"%m_%d_%H_%M\")\n",
    "\n",
    "trainable_with_resources = tune.with_resources(train_gliner,{\"cpu\":7,\"gpu\": 1})\n",
    "max_concurrent_trials = torch.cuda.device_count()\n",
    "\n",
    "## with search algorithm\n",
    "algo = OptunaSearch()\n",
    "\n",
    "# Hyperparameter search space\n",
    "search_space = {\n",
    "    \"lr\": tune.quniform(10e-5, 30e-5, 2e-5),\n",
    "    \"others_lr\": tune.quniform(3e-5, 10e-5, 1e-5),\n",
    "    \"max_steps\": tune.choice([400]),\n",
    "    \"weight_decay\": tune.quniform(0.03, 0.07, 0.01),\n",
    "    \"scheduler\": tune.choice([\"linear\"]), \n",
    "    'batch_size': tune.choice([32]),\n",
    "    \"max_grad_norm\": tune.quniform(0.3, 0.8, 0.1),\n",
    "    \"optim\": tune.choice(['adamw_torch_fused'])\n",
    "}\n",
    "wb_project = f\"raytune_gliner_{formatted_datetime}\"\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    trainable_with_resources,\n",
    "    param_space=search_space,\n",
    "    tune_config=tune.TuneConfig(\n",
    "        num_samples=10,\n",
    "        search_alg=algo,\n",
    "        metric=\"f1\",\n",
    "        mode=\"max\",\n",
    "        max_concurrent_trials=max_concurrent_trials,\n",
    "        scheduler=ASHAScheduler(grace_period=30)\n",
    "    ),\n",
    "    run_config=train.RunConfig(\n",
    "        callbacks=[WandbLoggerCallback(project=wb_project)],\n",
    "        storage_path=\"~/raytune/checkpoint\"\n",
    "    ),\n",
    ")\n",
    "results = tuner.fit()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d3e72a00-f7a6-4dde-af8a-07d926485990",
   "metadata": {},
   "source": [
    "dfs = {result.path: result.metrics_dataframe for result in results}\n",
    "# Plot by epoch\n",
    "ax = None  # This plots everything on the same plot\n",
    "for d in dfs.values():\n",
    "    ax = d.f1.plot(ax=ax, legend=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "37bdb098-6a46-4150-a298-3887b922da62",
   "metadata": {},
   "source": [
    "best_result = results.get_best_result(\"f1\", mode=\"max\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cc1eb28a-93e0-4d14-ae4b-e045f9c96d89",
   "metadata": {},
   "source": [
    "best_result"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7450a422-3401-4a5a-ac5f-3f0406358bf1",
   "metadata": {},
   "source": [
    "best_result.path"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3269c572-ef4b-47cb-b394-5007f480e7ff",
   "metadata": {},
   "source": [
    "# NOTE: Raytune doesn't keep track of the best iteration (checkpoint) with the current version and with the current evaluation setup, make sure to select the best model path and checkpoint based on the F1 chart from your reporting tool (e.g. WandB or Tensorboard)\n",
    "md = GLiNER.from_pretrained(f'{best_result.path}/checkpoint-400', load_tokenizer=True, local_files_only=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "de3690c8-e71d-46de-80c7-7bf3d71e4816",
   "metadata": {},
   "source": [
    "sentences = ds['validation']['sentence'][:]\n",
    "labels = ['Skill', 'Knowledge']\n",
    "y = ds['validation']['knowledge_and_skill'][:]\n",
    "\n",
    "pred_gli = []\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "md.to(device)\n",
    "batch_size = 64\n",
    "for i in range(0, len(sentences), batch_size):\n",
    "    # Yield successive batches of size batch_size\n",
    "    text = sentences[i:i + batch_size]\n",
    "    entities = md.batch_predict_entities(text, labels, threshold=0.89)\n",
    "    pred_gli.extend(entities)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4f74a609-32d4-45f2-9ca0-307196eb7a65",
   "metadata": {},
   "source": [
    "def proc_threshold(threshold):\n",
    "    pred_gli_threshold = []\n",
    "    for i in pred_gli:\n",
    "        if len(i) ==0:\n",
    "            pred_gli_threshold.append(i)\n",
    "        else:\n",
    "            pred_gli_threshold.append([j for j in i if j['score']> threshold])\n",
    "            \n",
    "    evaluator = Evaluator(y, pred_gli_threshold, tags=['Skill', 'Knowledge'])\n",
    "    results, results_per_tag, result_indices, result_indices_by_tag = evaluator.evaluate()\n",
    "    f1 = results['strict']['f1']\n",
    "    return {\"threshold\": threshold, 'f1': f1}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c84aad5b-7ef0-4d31-a2b5-f67fb306420f",
   "metadata": {},
   "source": [
    "from joblib import Parallel, delayed\n",
    "res = Parallel(n_jobs=-1)(delayed(proc_threshold)(i / 100) for i in range(5, 100, 1))\n",
    "res"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Select the threshold For GLiNER based on the best performance on the dev set\n",
    "threshold = pd.DataFrame(res).sort_values(by='f1', ascending=False).iloc[0]['threshold']"
   ],
   "id": "effd13ac3de40f43",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "85203f5d-bd9f-4409-bdf3-9c45d6ac1799",
   "metadata": {},
   "source": [
    "sentences = ds['validation']['sentence'][:]\n",
    "labels = ['Skill', 'Knowledge']\n",
    "y = ds['validation']['knowledge_and_skill'][:]\n",
    "\n",
    "pred_gli = []\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "md.to(device)\n",
    "batch_size = 64\n",
    "for i in range(0, len(sentences), batch_size):\n",
    "    # Yield successive batches of size batch_size\n",
    "    text = sentences[i:i + batch_size]\n",
    "    entities = md.batch_predict_entities(text, labels, threshold=threshold)\n",
    "    pred_gli.extend(entities)\n",
    "evaluator = Evaluator(y, pred_gli, tags=['Skill', 'Knowledge'])\n",
    "results, results_per_tag, result_indices, result_indices_by_tag = evaluator.evaluate()\n",
    "results['strict']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2603a0d5-8cc7-43fb-b0ce-df9a76141add",
   "metadata": {},
   "source": "{entity: entity_metric['strict'] for entity, entity_metric in results_per_tag.items()}",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "91833b46a6bf1e1b",
   "metadata": {},
   "source": [
    "sentences = ds['test']['sentence'][:]\n",
    "labels = ['Skill', 'Knowledge']\n",
    "y = ds['test']['knowledge_and_skill'][:]\n",
    "\n",
    "pred_gli = []\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "md.to(device)\n",
    "batch_size = 64\n",
    "for i in range(0, len(sentences), batch_size):\n",
    "    # Yield successive batches of size batch_size\n",
    "    text = sentences[i:i + batch_size]\n",
    "    entities = md.batch_predict_entities(text, labels, threshold=threshold)\n",
    "    pred_gli.extend(entities)\n",
    "evaluator = Evaluator(y, pred_gli, tags=['Skill', 'Knowledge'])\n",
    "results, results_per_tag, result_indices, result_indices_by_tag = evaluator.evaluate()\n",
    "results['strict']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a8cdd3dc-6ec3-4a73-ad1c-e4d37aef05ce",
   "metadata": {},
   "source": "{entity: entity_metric['strict'] for entity, entity_metric in results_per_tag.items()}",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "584b1869-6006-4236-aa9e-36678c43b9e1",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
